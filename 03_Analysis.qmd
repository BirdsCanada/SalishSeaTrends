---
title: "Analysis and Mapping"
format: html
editor: visual
editor_options: 
  chunk_output_type: console
---

Run the setup if starting a new environment and load previously saved data and filter for analysis.

```{r}

source("Scripts/00_Setup.R")

#Manually Specify the start and end year of the analysis. 
Y1 = 2008
Y2 = 2024

#Manually specify the area of the analysis
area <- "SALISHSEA" #one word to be compatible with the code.
#area <- "BCCWS"
#area <- "PSSS"


#Load your saved species data and filter for years and area
sp.data<-read.csv("Data/sp.data.csv")
sp.data <- sp.data %>% filter(wyear >= Y1 & wyear <= Y2)

if(area != "SALISHSEA") {
  sp.data <- sp.data %>% filter(ProjectCode == area)
}

# Load your saved events data which is needed for zero-filling
events <- read.csv("Data/events.csv")
events <- events %>% filter(wyear >= Y1 & wyear <= Y2)

if(area != "SALISHSEA") {
  events <- events %>% filter(ProjectCode == area)
}

#Load the Salish Sea Water Polygon for graphing results 
map<- st_read("Data/Spatial/Salish_Sea_Water_Polygon.shp")

#ensure the coordinate reference systems are the same
mapCRS<-st_crs(map) #get the CRS of the poly data

model<-"iCAR"

#Create a spatial points layers for graphing results
loc<-events %>% select(SurveyAreaIdentifier, DecimalLatitude, DecimalLongitude) %>% distinct()
xy<-st_as_sf(loc, coords = c("DecimalLongitude", "DecimalLatitude"))
st_crs(xy)<-"+proj=longlat +datum=NAD83"
xy<-st_transform(xy, mapCRS) #transform 


```

## Set Analysis Parameters {#3.1Analysis}

Here the user has several customization options.

Upload the desired spatial polygon for the analysis. We use "Watersheds in the Salish Sea Bioregion" layer from the [Salish Sea Atlas Data](#0) as an example.

```{r}
  assignment_method <- "within"  
# assignment_method <- "nearest"
  
# Load and prepare polygon
  poly <- st_read("Data/Spatial/Salish_Sea_Watersheds.shp") %>% 
    st_make_valid() %>% 
    st_transform(st_crs(mapCRS))  # Ensure CRS matches points
  
#List available fields for user selection
  print(names(poly))

#Prompt user to select polygon ID and area fields
  polygon_id_field <- "Name" #Enter the field name for polygon ID (e.g., 'WatershedID')
  area_field <- "" #Enter the field name for area (or leave blank if none or you desire equal weights)

#Rename fields to 'Name' and 'Area'. If polygon area is missing, this will be created and assigned to 1. Analytically, this means the "Study Area" trend will be equally weighted across all polygons. 
  poly <- poly %>%
  rename(Name = !!polygon_id_field) %>%
  mutate(Area = if (area_field != "") .data[[area_field]] else 1)
  
#Assignment method   
 if (assignment_method == "within") {
  # Assign points to polygons only if strictly within
  xy_assigned <- st_join(xy, poly, join = st_within)
} else if (assignment_method == "nearest") {
  # Assign each point to the nearest polygon
  nearest_poly_index <- st_nearest_feature(xy, poly)
  xy_assigned <- xy
  xy_assigned$Name <- poly$Name[nearest_poly_index]
  xy_assigned$Area <- poly$Area[nearest_poly_index]
} else {
  stop("Unknown assignment method.")
}

# Drop polygons with no assigned points
used_names <- unique(na.omit(xy_assigned$Name))
poly <- poly %>% filter(Name %in% used_names)


 # Create grid table
grid <- xy_assigned %>%
  st_drop_geometry() %>%
  filter(Name %in% poly$Name) %>%
  select(SurveyAreaIdentifier, Name, Area) %>%
  distinct() %>%
  mutate(alpha_i = as.integer(factor(Name)))%>% 
  drop_na(Name) #Drop unassigned point

# Merge grid info back to events
events <- events %>%
  left_join(grid, by = "SurveyAreaIdentifier") %>%
  drop_na(Name)

# Visualization
  spatial_plot <- ggplot() +
    geom_sf(data = poly, aes(fill = Name), color = "black") +
    geom_sf(data = xy, color = "black", size = 1) +
    theme_minimal()
  
  print(spatial_plot)
  ggsave(file.path(plot.dir, "iCAR_Spatial_Plot.jpeg"), 
         plot = spatial_plot, width = 8, height = 6, dpi = 300)

```

![Alt text for accessibility](Images/WatershedSampleMap.png)

### Species or Guild Specific Analysis {#3.1.2Analysis}

For a species-specific analysis, select the species you wish to analyse.

```{r}

#To view your options of species
species<-unique(sp.data$CommonName)
#view(species)

#Create a list of species using all available species in the dataset.
species.list<-tolower("All") #R is case sensitive

#Or you can manually select species. Ensure case and spelling is correct. 
#species.list <- c("American Wigeon", "Common Loon", "Large Gull") 


```

For a guild-specific analysis, change `guild` to "Yes" and specify the `type` as either "migration", "diet", or "family". This will override the species list above.

*You do not need to run this code chunk if doing a species-specific analysis. Default guild is set to "No" in the setup script.*

```{r}

guild <- "yes"

#To view your options of guilds
migration<-unique(sp.data$Migration)
#view(migration)

diet<-unique(sp.data$Diet)
#view(diet)

family<-unique(sp.data$family_name)
#view(family)

#select on of the options for the analysis
type <-"family"

```

### Minimum Data Requirement {#3.1.3Analysis}

Select the minimum data requirements for the analysis. The ones selected here were done following the inspection of the international dataset. However, finer scale assessment may need to assess their suitability.

```{r}

#The minimum data required across sites with at least one detection:

min.abundance <- 10 #Overall abundance per year > 10
min.years <- (Y2-Y1)/2 #Detected in > one-half of the survey years
nsites <- 10 #Detected at > 10 survey sites

```

### Model Specifications

Select the distributional family, and set random and spatial priors, or retain the defaults. These priors were selected based on model assessments for the full study area.

```{r}

#Here we select 'nbinomal' but this may need to adjust if there is residual overdispersion. 
fam<-'nbinomial'
#fam<-'poisson'

#Priors for the random effects
hyper.iid <- list(prec = list(prior = "pc.prec", param = c(1, 0.01)))

```

## Analysis {#3.2Analysis}

Create output tables to the `Output` folder using a custom file `name`.

The Output_Tables function creates is a file for Annual Indices, Trends, and a file with the Dispersion statistic.

```{r}

#Give your analytically output file a unique name (e.g., BCCWS_Species, SalishSea_Migration, Watershed_Species), 

name<-"Watershed_Family"

#This is the template used for the State of Canada's Birds and is required for upload into NatureCounts

#Create output tables, which will include your custom name and the `model` you specified.
output_tables(name, model)

```

You are ready to start your analysis! The analysis will write results to the files on in the `Output` folder and also create some plots for model checking.

```{r}

run_analysis(model)

```

Note that the Dispersion Statistic file in the `Output` folder should be reviewed after the analysis. If the statistic is \> 10 you should inspect the FitPlots in the Plot directory. In this case we will want to rerun using a different distributional assumption on the counts. This can be done by manually changing the `fam` to Poisson and selecting these species to be rerun.

## Map Results {#3.3Vis}

Finally, you can visualize your results.

```{r}

 graph_results(name)

```

![Alt text for accessibility](Images/iCAR_SalishSea_SpeciesWEGR.png)

[
  {
    "objectID": "03_Analysis.html",
    "href": "03_Analysis.html",
    "title": "3  Analysis and Visualization",
    "section": "",
    "text": "3.1 Set Analysis Parameters\nHere the user has several customization options.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Analysis and Visualization</span>"
    ]
  },
  {
    "objectID": "03_Analysis.html#3.1Analysis",
    "href": "03_Analysis.html#3.1Analysis",
    "title": "3  Analysis and Visualization",
    "section": "",
    "text": "3.1.1 Model Type\nYou can choose the continuous space “SPDE” or discrete space “iCAR” method.\n\n#model&lt;-\"iCAR\"\nmodel&lt;-\"SPDE\"\n\nIf doing an SPDE model, you may define your area as “SalishSea”, “BCCWS”, or “PSSS”. Only sites with more than 10 years of data will be retained in the analysis.\n\nif(model == \"SPDE\"){\narea &lt;- \"SALISHSEA\" #one word to be compatible with the code.\n#area &lt;- \"BCCWS\"\n#area &lt;- \"PSSS\"\n}\n\nIf doing an iCAR model, upload the desired spatial polygon for the analysis. We use “Watersheds in the Salish Sea Bioregion” layer from the Salish Sea Atlas Data as an example.\nA polygon should have counts in all years to ensure that sampling is complete and consistent. Those that have incomplete time series are removed.\n\nif(model == \"iCAR\"){\n  \n#Load polygon shapefile\npoly &lt;- st_read(\"Data/Spatial/Salish_Sea_Watersheds.shp\") %&gt;% st_make_valid()\n\n#Check that your polygon is valid\nst_is_valid(poly)\n\n#List available fields for user selection\nprint(names(poly))\n\n#Prompt user to select polygon ID and area fields\npolygon_id_field &lt;- \"Name\" #Enter the field name for polygon ID (e.g., 'WatershedID')\narea_field &lt;- \"\" #Enter the field name for area (or leave blank if none or you desire equal weights)\n\n#Rename fields to 'Name' and 'Area'. If polygon area is missing, this will be created and assigned to 1. Analytically, this means the \"Study Area\" trend will be equally weighted across all polygons. \npoly &lt;- poly %&gt;%\n  rename(Name = !!polygon_id_field) %&gt;%\n  mutate(Area = if (area_field != \"\") .data[[area_field]] else 1)\n\n#Spatially filter the polygon to those that have points\npoly &lt;- st_transform(poly, st_crs(mapCRS))\nGrid &lt;- poly %&gt;% st_filter(xy, .predicate = st_intersects)\nloc.xy &lt;- st_join(Grid, xy)\n\n#Spatially filter the point to those that are only contained within the polygon\npoints &lt;- st_filter(xy, Grid, .predicate = st_within)\n\n#Visualize\nplot &lt;- ggplot() +\n  geom_sf(data = Grid, aes(fill = Name), color = \"black\") +\n  geom_sf(data = points, color = \"black\", size = 1) +\n  theme_minimal()\n\nprint(plot)\n\nggsave(\n  filename = file.path(plot.dir, \"iCAR_Spatial_Plot.jpeg\"),\n  plot = plot,\n  width = 8,\n  height = 6,\n  dpi = 300\n)\n\n#Create the grid table that links the polygon ID to the SurveyAreaIdentifier\ngrid &lt;- loc.xy %&gt;%\n  st_drop_geometry() %&gt;%\n  select(SurveyAreaIdentifier, Name, Area) %&gt;%\n  distinct() %&gt;%\n  mutate(\n    alpha_i = as.integer(factor(Name))\n  )\n\n#Joint to your events layer and drop survey points outside the polygon\nevents &lt;- left_join(events, grid, by = \"SurveyAreaIdentifier\") %&gt;% drop_na(Name)\n}\n\n\n\n\nAlt text for accessibility\n\n\n\n\n3.1.2 Species or Guild Specific Analysis\nFor a species-specific analysis, select the species you wish to analyse.\n\n#To view your options of species\nspecies&lt;-unique(sp.data$CommonName)\n#view(species)\n\n#Create a list of species using all available species in the dataset.\nspecies.list&lt;-tolower(\"All\") #R is case sensitive\n\n#Or you can manually select species. Ensure case and spelling is correct. \n#species.list &lt;- c(\"American Wigeon\", \"Common Loon\", \"Large Gull\") \n\nFor a guild-specific analysis, change guild to “Yes” and specify the type as either “migration”, “diet”, or “family”. This will override the species list above.\nYou do not need to run this code chunk if doing a species-specific analysis. Default guild is set to “No” in the setup script.\n\nguild &lt;- \"yes\"\n\n#To view your options of guilds\nmigration&lt;-unique(sp.data$Migration)\n#view(migration)\n\ndiet&lt;-unique(sp.data$Diet)\n#view(diet)\n\nfamily&lt;-unique(sp.data$family_name)\n#view(family)\n\n#select on of the options for the analysis\ntype &lt;-\"migration\"\n\n\n\n3.1.3 Minimum Data Requirement\nSelect the minimum data requirements for the analysis. The ones selected here were done following the inspection of the International dataset. However, finer scale assessment may need to assess their suitability.\n\n#The minimum data required across sites with at least one detection:\n\nmin.abundance &lt;- 10 #Overall abundance per year &gt; 10\nmin.years &lt;- (Y2-Y1)/2 #Detected in &gt; one-half of the survey years\nnsites &lt;- 10 #Detected at &gt; 10 survey sites\n\n\n\n3.1.4 Model Specifications\nSelect the distributional family, and set random and spatial priors, or retain the defaults. These priors were selected based on model assessments for the full study area.\n\n#Here we select 'nbinomal' but this may need to adjust if there is residual overdispersion. \n\nfam&lt;-'nbinomial'\n#fam&lt;-'poisson'\n\n#Priors for the random effects\nhyper.iid &lt;- list(prec = list(prior = \"pc.prec\", param = c(1, 0.01)))\n\n#SPDE spatial priors\nprior.range = c(20, 0.5)  # 50% probability range &gt;20 km  \nprior.sigma = c(1, 0.1)   # 10% probability stdev &gt;1 \n\n\n\n\nAlt text for accessibility",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Analysis and Visualization</span>"
    ]
  },
  {
    "objectID": "03_Analysis.html#3.2Analysis",
    "href": "03_Analysis.html#3.2Analysis",
    "title": "3  Analysis and Visualization",
    "section": "3.2 Analysis",
    "text": "3.2 Analysis\nCreate output tables to the Output folder using a custom file name.\nThe files that this code creates is a file for Annual Indices for each sampling site, end-point Trends, and a file with the Dispersion statistic.\nYou are ready to start your analysis! The analysis will write results to the files on the folder and also create some plots for model checking.\n\n#Give your analytically output file a unique name (e.g., BCCWS_Species, SalishSea_Migration, Watershed_Species), \n\nname&lt;-\"Salish_Species\"\n\n#This is the template used for the State of Canada's Birds and is required for upload into NatureCounts\n\n#Create output tables, which will include your custom name and the `model` you specified.\noutput_tables(name, model)\n\n#Now we can initiate the analysis based on the `model` you previously specified.   \nrun_analysis(model)\n\nNote that the Dispersion Statistic file in the Output folder should be reviewed after the analysis. If the statistic is &gt; 10 you should inspect the FitPlots in the Plot directory. In this case we will want to rerun using a different distributional assumption on the counts. This can be done by manually changing the fam to Poission and selecting these species to be rerun.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Analysis and Visualization</span>"
    ]
  },
  {
    "objectID": "03_Analysis.html#3.3Vis",
    "href": "03_Analysis.html#3.3Vis",
    "title": "3  Analysis and Visualization",
    "section": "3.3 Results",
    "text": "3.3 Results\nThe analysis calculates trends using both the end point method and a slope through the calculated annual indices of abundance. When mapping the results, the user needs to select which trend outputs they would like to view as either “Endpoint” or “Slope”. Given these models are\n\ntrend &lt;- \"Slope\" \n#trend &lt;- \"Endpoint\"\n\n#Graph your outputs\ngraph_results(model, name, trend)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Analysis and Visualization</span>"
    ]
  },
  {
    "objectID": "02_DataAccess.html",
    "href": "02_DataAccess.html",
    "title": "2  Data Access and Cleaning",
    "section": "",
    "text": "2.1 British Columbia Coastal Waterbird Survey (BCCWS)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data Access and Cleaning</span>"
    ]
  },
  {
    "objectID": "02_DataAccess.html#2.1Data",
    "href": "02_DataAccess.html#2.1Data",
    "title": "2  Data Access and Cleaning",
    "section": "",
    "text": "2.1.1 Protocol\nBCCWS data collection protocol can be found online here.\nIn short, surveys have been conducted by volunteers using a standardized protocol and data collection sheets. Shore-based counts are completed monthly on or near the second Sunday of each month from September to April. Surveys are complete within approximately 2 hours of high tide to maximize the opportunity for close observation. All waterbirds observed to a distance of 1 km from the high tide line are counted, except those that fly through without stopping. In the case of larger flocks, numbers are estimated by counting individuals and species in groups and scaling up (see Training Module for Volunteers). Data are entered through a customized online data entry system available on the Birds Canada website, NatureCounts. Observations are processed using the eBird data filters to flag rare species and high counts during observer data entry, and records are manually reviewed for form accuracy.\nThe data are collected using a standardized protocol, by trained citizen-science volunteers. This standardization is a strength of this data set for making inferences about coastal waterbirds in the Canadian Salish Sea.\n\n\n2.1.2 Data Collected\nObservation counts of waterbirds and raptor seen during a survey are compiled at the scale of the route (i.e., the maximum count per species) on each monthly survey. These observations are divided into inland, near shore (shoreline to 500m out from high tide), off shore (beyond 500m), and total counts. The dataset is not zero-filled.\nAuxiliary Data Collected:\n\nObserver information: observer ID\nSurvey information: time observation started, time observation ended, duration in hours\nSurvey condition: precipitation, % cloud, sea condition, tide state, tide movement, visibility, survey equipment, human activity (all categorical)\n\n\n\n2.1.3 Data Access\nData can be freely accessed through the NatureCounts data download portal or directly through the naturecounts R package. The BCCWS is Access Level 4 dataset, meaning a data request form must be submitted. This is not meant to be a barrier, rather a means of keeping track of who is using the data and for what purposes.\nData are formatted using a standardized schema that is a core standard of the Avian Knowledge Network and which feeds into GBIF. This format is called the Bird Monitoring Data Exchange (BMDE), which includes 169 core fields for capturing all metric and descriptors associated with bird observations.\n\n#Sample code to access BCCWS data from NatureCounts\n BCCWS_BMDE&lt;-nc_data_dl(collection=\"BCCWS\", username = \"YOUR USERNAME\", info=\"MY REASON\", fields_set = \"extended\", request_id = 12345)\n\n#Write raw data to the `Data` folder in working directory\nwrite.csv(BCCWS_BMDE, \"Data/BCCWS_BMDE.csv\", row.names = FALSE)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data Access and Cleaning</span>"
    ]
  },
  {
    "objectID": "02_DataAccess.html#2.2Data",
    "href": "02_DataAccess.html#2.2Data",
    "title": "2  Data Access and Cleaning",
    "section": "2.2 Puget Sound Seabird Survey (PSSS)",
    "text": "2.2 Puget Sound Seabird Survey (PSSS)\n\n2.2.1 Protocol\nPSSS data collection protocol can be found online here.\nIn short, surveys are conducted by volunteers using a standardized protocol and data collection sheets. Shore-based counts are completed monthly on the first Saturday of each month from October to April. Surveys are completed within approximately 2 hours of high tide to maximize the opportunity for close observation. Surveys are a minimum of 15 minutes and a maximum of 30 minutes per site. All waterbirds observed to a distance of 300 m from the high tide line are counted, except those that fly through without stopping. For large flocks, surveys estimate both the min, max, and best estimate. Surveyors are required to attend a short training session with Puget Sound Bird Observatory staff prior to their first survey. Data are entered through a customized online data entry system, available here.\nThe data are collected using a standardized protocol, by trained citizen-science volunteers. This standardization is a strength of this dataset for making inferences about coastal waterbirds in the US Salish Sea.\n\n\n2.2.2 Data Collected\nTotal observation counts of each waterbird species seen during a point survey are recorded, including bearing, distance, and sex ratio. Raptors are recorded separately from the other waterbird species. The dataset is not zero-filled.\nAuxiliary Data Collected:\n\nObserver information: observer name\nSurvey information: time observation started, time observation ended\nSurvey condition: weather, precipitation, sea state, tide movement, visibility, human activity, raptor activity (all categorical)\n\n\n\n2.2.3 Data Access\nAt the time of writing, the data were only accessible by reaching out to the Puget Sound Bird Observatory directly and filling out a data share agreement. The data will be sent to you as a .csv flat file which will be suitable for Data formatting and processing. Ensure that you receive all the data for the specified temporal period you are interested in analyzing. This will be needed to allow for proper zero-filling. Place the data in a Data folder in your working directory.\n\n\n2.2.4 Data Format\nThe PSSS is in a different format than the BCCCW, and therefore requires a separate data processing step to wrangle the data into the 169 core fields of the Bird Monitoring Data Exchange (BMDE). The following function will do this step for you.\n\n# Call the function passing the file path into the PSSS_BMDE function\n\nPSSS_BMDE &lt;- psss_to_bmde(\"Data/psss20250313.csv\")",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data Access and Cleaning</span>"
    ]
  },
  {
    "objectID": "02_DataAccess.html#2.3Data",
    "href": "02_DataAccess.html#2.3Data",
    "title": "2  Data Access and Cleaning",
    "section": "2.3 Clean and Combine",
    "text": "2.3 Clean and Combine\nNow it is time to do some data cleaning before we combine the BCCWS and PSSS datasets. The user has the opportunity here to select the start and end dates of the analysis by changing the Y1 and Y2 variables.\nDuring this process some species are combined following advise from the survey coordinators. These are species that are typically difficult to tell apart and are often misidentified.\n\n“Large Gull” = gull (large) + WEGU + GWGU hybrid + Glaucous-winger + Western + Herring + Glaucous + Iceland (Thayer’s) + California Gull\n“Greater-Lesser Scaup” = scaup sp + Lesser + Greater Scaup\n“Eared-Horned Grebe”\n“Western-Clark’s Grebe”\n“Canada-Cackling Goose”\n\nOther non-target species are also removed i.e., any species detected less than 10 times over all years is considered rare and removed.\nThis part of the code also creates and events martix for each program. This is what is used for zero-filling during the species or guild specific analysis.\n\nwmonth = MonthCollected (1=September to 8=April)\nwyear\nObservationCount3 for BCCWS to match PSSS protocol\nSampling events matrix\n\n\n#Manually specify the start and end year of the analysis\n#Keep in mind that this is the winter year (wyear) which is the start year of the survey\n#The survey straddles two calendar years\nY1 = 2008\nY2 = 2023\n\nclean_BCCWS&lt;-clean_BCCWS(Y1, Y2)\nclean_PSSS&lt;-clean_PSSS(Y1, Y2)\n\nCombine the clean datasets and events tables\n\n#Access clean data\nin.BCCWS &lt;- clean_BCCWS$in.BCCWS\nin.PSSS &lt;- clean_PSSS$in.PSSS\n\n#Access events data\nevent.PSSS &lt;- clean_PSSS$event.PSSS\nevent.BCCWS &lt;- clean_BCCWS$event.BCCWS\n\n#Combine and write the data to you Data folder\nin.data&lt;-rbind(in.BCCWS, in.PSSS)\nevents&lt;-rbind(event.BCCWS, event.PSSS)\n\n# To write to local Data directory\nwrite.csv(in.data, \"Data/in.data.csv\", row.names = FALSE)\nwrite.csv(events, \"Data/events.csv\", row.names = FALSE)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data Access and Cleaning</span>"
    ]
  },
  {
    "objectID": "02_DataAccess.html#2.4Data",
    "href": "02_DataAccess.html#2.4Data",
    "title": "2  Data Access and Cleaning",
    "section": "2.4 Species Filtering",
    "text": "2.4 Species Filtering\nNot all species will be included in an analysis. Some species are detected too infrequently to be included or they may not be species of focus for your study area. In the next section, you will be given the option to manually select focal species or guilds for the analysis.\nHere we filter for species that are detected by both surveys. Generally, PSSS monitors just targets, whereas the BCCWS monitors more non-targets. In the analysis script we will set some additional minimum data requirements to remove species that do not have enough data to estimate trends.\n\n#Determine which SpeciesCode each ProjectCode share in the full dataset\nsp.bccws&lt;-in.data %&gt;% filter(ProjectCode == \"BCCWS\") %&gt;% dplyr::select(CommonName) %&gt;% distinct()\nsp.psss&lt;-in.data %&gt;% filter(ProjectCode == \"PSSS\") %&gt;% dplyr::select(CommonName) %&gt;% distinct()\n\ncommon.species&lt;-intersect(sp.bccws$CommonName, sp.psss$CommonName) \n#There were 53 species in common between BCCWS and PSSS that are carried forward for the analysis\n\n#filter the full dataset to only include the common species\nsp.data&lt;-in.data[in.data$CommonName %in% common.species,]\n\n#write to Data folder in working directory\nwrite.csv(sp.data, \"Data/sp.data.csv\", row.names = FALSE)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data Access and Cleaning</span>"
    ]
  },
  {
    "objectID": "02_DataAccess.html#2.5Data",
    "href": "02_DataAccess.html#2.5Data",
    "title": "2  Data Access and Cleaning",
    "section": "2.5 Guild Assignment",
    "text": "2.5 Guild Assignment\nThe user may be interested in assigning species to Guilds for their analysis. In the Data folder we provide the user with migration and dietary guilds for the 53 species that the survey programs have in common. We can also assign species to family using the NatureCounts metadata, which can be accessed using the R package.\nThe user may wish to review and update this .csv as needed, as new species might be added that are not currently on the list.\n\nguild&lt;-read.csv(\"Data/GuildList.csv\")\nguild&lt;-guild[guild$english_name %in% common.species,]\n\nfamily&lt;-meta_species_taxonomy() %&gt;% select(species_id, group_id, family_name, family_english_name)\n\nguild&lt;-left_join(guild, family, by=c(\"species_id\"))\n\nsp.data&lt;-left_join(sp.data, guild, by=c(\"CommonName\" = \"english_name\"))\n\n#write to Data folder in working directory\nwrite.csv(sp.data, \"Data/sp.data.csv\", row.names = FALSE)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data Access and Cleaning</span>"
    ]
  },
  {
    "objectID": "02_DataAccess.html#2.6Data",
    "href": "02_DataAccess.html#2.6Data",
    "title": "2  Data Access and Cleaning",
    "section": "2.6 Sampling Events Plot",
    "text": "2.6 Sampling Events Plot\nNow we will plot the distribution of sampling events over the extent of the Salish Sea. This will be facets by year (wyear) so that changes in sampling effort can be spatially visualized. Each survey program will be given a different colour.\nNotice that in 2020, sampling was reduced in Canada and did not happen in the US due to COVID-19. We will therefore remove this wyear during the analysis.\n\n#Convert the data to a spatial object\nevents_sf &lt;- st_as_sf(events, coords = c(\"DecimalLongitude\", \"DecimalLatitude\"), crs = 4326)\n\nggplot(data = events_sf) +\n  # Select a basemap\n  annotation_map_tile(type = \"cartolight\", zoom = NULL, progress = \"none\") +\n  # Plot the points, color-coded by survey_year\n  geom_sf(aes(color = as.factor(wyear)), size = 1) +\n  # Facet by survey_year to create the multi-paneled map\n  facet_wrap(~ wyear) +\n  # Add a theme with a minimal design and change the font styles, to your preference\n  theme_minimal() +\n  #theme(legend.position = \"bottom\") +\n  # To make the points in the legend larger without affecting map points\n  guides(color = guide_legend(override.aes = list(size = 3))) +\n  #make the text on the x-axis vertical\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +\n  # Define the title and axis names\n  labs(title = \"Coastal Waterbird Survey Events in the Salish Sea\",\n       x = \"Longitude\",\n       y = \"Latitude\")+\n  #Define the legend title\n  scale_color_discrete(name = \"Winter Year\")\n\n\n\n\nAlt text for accessibility",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data Access and Cleaning</span>"
    ]
  },
  {
    "objectID": "99_Resources.html",
    "href": "99_Resources.html",
    "title": "4  Resources",
    "section": "",
    "text": "4.1 Birds Canada GitHub\nAll R scripts and resources associated with this project, as well as many other tools and tutorials, are available on the Birds Canada GitHub page.\nThis repository is regularly updated and serves as the central hub for sharing code related to Birds Canada’s monitoring and research programs. If you run into issues using this code, or it generates errors, please open a git issue of email dethier@birdscanada.org.\nTo access the code visit: https://github.com/BirdsCanada/SalishSeaTrends\nYou can view files directly on GitHub, or download individual scripts and entire repositories by clicking the green Code button and selecting Download ZIP.\nFor advanced users, you can clone repositories using Git into RStudio using the following command in the Terminal:\ngit clone https://github.com/BirdsCanada/SalishSeaTrends.git\nFor tutorials and additional resources on using the NatureCounts R package, see the NatureCounts package website.\nIf you are new to GitHub, Birds Canada also provides a Beginner’s Guide to GitHub with step-by-step instructions for accessing and sharing code.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Resources</span>"
    ]
  },
  {
    "objectID": "99_Resources.html#accessing-code-on-the-birds-canada-github",
    "href": "99_Resources.html#accessing-code-on-the-birds-canada-github",
    "title": "4  Resources",
    "section": "",
    "text": "00_Setup.R\nAnalysis_iCAR.R\nAnalysis_SPDE.R\nBCCWSClean.R\nPSSSClean.R\nGraph_iCAR.R\nGraph_SPDE.R\nOutputTables.R\nPSSSBMDE.R",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Resources</span>"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Transboundary coastal waterbird trends in the Salish Sea",
    "section": "",
    "text": "0.1 Goals\nThe goals of this user guide is to empower resource managers to leverage standardized citizen-science monitoring data, collected by the BCCWS and PSSS, to (1) obtain scientifically credible measures of abundance trends of coastal waterbirds in the transboundary waters of the Salish Seas at scales appropriate for resource management, (2) identify priority species for conservation, and (3) provide resource managers with openly accessible annual indices of abundance for model-based management planning. In turn, these modelling outputs can be used to assess environmental and human-induced mechanisms of waterbird changes and provide a foundation from which to tease apart whether local population fluctuations are a result of true changing abundance or shifts in species distributions over time.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Overview</span>"
    ]
  },
  {
    "objectID": "index.html#1.2Intro",
    "href": "index.html#1.2Intro",
    "title": "Transboundary coastal waterbird trends in the Salish Sea",
    "section": "0.2 Methods",
    "text": "0.2 Methods\nThe user can choose from one of two spatially explicit analytical approaches. Both use spatially varying coefficients (SVCs, Gelfand et al. 2003) to account for relationships between variables (in this case counts of birds) that are not uniform across large spatial areas. This modelling approach was first applied to continent wide bird abundance data to assess winter bird population trends using discrete aerial units (Meehan et al. 2019) and an intrinsic conditional autoregressive model (iCAR; Besag 1974). The modelling framework was later adapted (Meehan et al. 2024) to incorporate continuous space using a triangulated model mesh and stochastic partial differential equation (SPDE; Lindgren et al. 2022). The benefits of a continuous-space (SPDE) versus a discrete-space (iCAR) models are (1) finer resolution of trends, (2) a better understanding of the range of spatial correlation, and (3) a reduction in boundary effects associated with discrete-space analyses. However, many management units (such as geopolitical boundaries) are divided by discrete polygons, making the iCAR approach appropriate in many instances. We therefore develop workflows which allows for both an iCAR and SPDE SCV approach to derive estimates of annual relative abundance as well as long-term trends of coastal waterbirds in the Salish Sea.\nDetails on data collection and processing can be found in the next section of this user guide\nThe basic statistical unit for the analysis was the maximum yearly count of each species at a survey site. We initially structured the analysis at a monthly resolution, treating monthly counts at site as our response variable. However, model diagnostics revealed convergence failures and inflated variance components indicating poor identifiable of monthly effects. To balance temporal resolution with model stability, we aggregated counts to the maximum yearly count at each survey site. This aggregation reduced overdispersion while maintaining ecological relevance.\nSpecies must meet the minimum data requirements in order to be included in the analysis. By default, these include (1) minimum annual abundance &gt;10 individuals across all sites, (2) detection in &gt;50% of study years (specifically &gt;(Y₂-Y₁)/2 years where Y₁ and Y₂ represent the study period endpoints), and (3) presence at &gt;10 distinct monitoring locations. Minimum data filters can be adjusted by users before running the analysis.\nExtreme outliers in observation counts are identified using a quantile-based threshold. We calculated the outlier cutoff as three times the 99th percentile of the maximum observation count. This was done to prevent disproportionate influence from rare extreme values and to aid in model fit. Data from 2020 were also removed to due survey disruptions caused by COVID-19.\nWe modeled the maximum observed counts yₐₜ at site a and year t using a negative binomial distribution: yₐₜ ∼ NB(μₐₜ, ϕ) where μₐₜ = exp[log(Dₐₜ) + β₀ + fₜ + γₖ + α(sₐ)]. The linear predictor incorporated survey duration Dₐₜ as an offset, a global intercept β₀, a temporal parameter γₖ with an independent and identically distributed (IID) random effect to allow for random fluctuations in counts from year to year, and a site-level random effects fₜ with IID.\nThe spatial component on abundance α(sₐ) uses either the SPDE or iCAR approach. This is user defined before running the analysis.\nThe SPDE approach uses a mesh, featuring maximum edge lengths of 25 km (inner domain) and 50 km (outer buffer), minimum vertex spacing of 2 km, and boundary constraints derived from coastline geometry. For the spatial range parameter, we set the prior such that there was a 50% probability that the spatial correlation range exceeded 20 km (i.e., P(range &gt; 20 km) = 0.5). For the spatial standard deviation, we set the prior so that there was a 10% probability that the marginal standard deviation exceeded 1 (i.e., P(σ &gt; 1) = 0.1). These priors provide weakly informative regularization, reflecting plausible spatial scales and variation while avoiding over fitting. These priors can be adjusted by users before running an analysis.\nThe iCAR approach assigned spatially structured random intercepts for each provided polygon based on the neighborhood structure. This allowed for information on relative abundance to be shared across neighbouring cells. Values of α(sₐ) came from a normal distribution with a mean value related to the average of adjacent cells and with a conditional variance proportional to the variance across adjacent cells and inversely proportional to the number of adjacent cells. We provide an example using the “Watersheds in the Salish Sea Bioregion” layer from the Salish Sea Atlas Data. The user can upload a multipolygon spatial layer, which covers part or all of the Salish Sea to run the analysis for their management jurisdictions of interest.\nModels were fitted via integrated nested Laplace approximation (INLA) with 1,000 posterior samples drawn for uncertainty quantification. We computed annual abundance indices Ñₜ by summing exponentiated linear predictos of abundances, then derived trends using the endpoint and slope methods.\n\nEndpoint Trend = 100 × [(Ñ_Y₂/Ñ_Y₁)^{1/(Y₂-Y₁)} - 1].\nSlope Trend = 100 x (exp(coef(lm(log(NY) ~ Y))[2]) - 1)\n\nCredible intervals reflected the 2.5% and 97.5% quantiles of posterior trend estimates, with interval width calculated as their difference. The iCAR model also produces area-weighted composite indices of abundance, where weights are assigned by the user as being equal or based on the polygon area.\nFor analyses conducted at the guild level, we included an additional species-level random effect, also modeled with an IID, to account for unstructured heterogeneity among species.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Overview</span>"
    ]
  },
  {
    "objectID": "index.html#1.3Intro",
    "href": "index.html#1.3Intro",
    "title": "Transboundary coastal waterbird trends in the Salish Sea",
    "section": "0.3 Results",
    "text": "0.3 Results\nSelect model outputs (national and international trends) are accessible through the naturecounts R package and will be made available through the web portal in late 2025. The outputs from this analysis will therefore provide resource managers with openly accessible annual indices of abundance for model-based management planning. User generated output will be stored in the output folder in the working directory of this project.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Overview</span>"
    ]
  },
  {
    "objectID": "index.html#using-this-technical-guide",
    "href": "index.html#using-this-technical-guide",
    "title": "Transboundary coastal waterbird trends in the Salish Sea",
    "section": "0.4 Using this Technical Guide",
    "text": "0.4 Using this Technical Guide\nIn this technical guide we detailing the analytical methods used to calculate broad- and fine-scale trends and annual indices of abundance for all species regularly monitored by the BCCWS and PSSS. Specifically, this guide will provide step-by-step instructions on (1) data access, (2) data wrangling and processing, (3) setting up the analysis for various spatial scales (continuous and discrete space), and (4) running the analysis and generating output tables and maps. This guide assumes that you have a basic understanding of R. We recommend that you become familiar with ‘R for Data Science’ by Garrett Grolemund and Hadley Wickham, which covers how to import, visualize, and summarize data in R using the tidyverse collection of R packages.\nR scripts and code resources associated with this project are available on the Birds Canada GitHub page and in the Resource section of this guide.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Overview</span>"
    ]
  },
  {
    "objectID": "index.html#1.4Intro",
    "href": "index.html#1.4Intro",
    "title": "Transboundary coastal waterbird trends in the Salish Sea",
    "section": "0.4 Using this Technical Guide",
    "text": "0.4 Using this Technical Guide\nThis guide provides users with step-by-step instructions on (1) data access, (2) data wrangling and processing, (3) setting up the analysis for various spatial scales (continuous and discrete space), and (4) running the analysis and generating output tables and maps. This guide assumes that you have a basic understanding of R.\nR scripts and data resources associated with this project are available on the Birds Canada GitHub page and in the Resource section of this guide. If you run into issues executing the code or it generates errors, please open a git issue, or send an email to dethier@birdscanada.org.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Overview</span>"
    ]
  },
  {
    "objectID": "99_Resources.html#downloadable-r-scripts",
    "href": "99_Resources.html#downloadable-r-scripts",
    "title": "4  Resources",
    "section": "4.2 Downloadable R Scripts",
    "text": "4.2 Downloadable R Scripts\nYou can download the R scripts used in this analysis below:\n\n00_Setup.R\nAnalysis_iCAR.R\nAnalysis_SPDE.R\nBCCWSClean.R\nPSSSClean.R\nGraph_iCAR.R\nGraph_SPDE.R\nOutputTables.R\nPSSSBMDE.R",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Resources</span>"
    ]
  },
  {
    "objectID": "99_Resources.html#downloadable-data",
    "href": "99_Resources.html#downloadable-data",
    "title": "4  Resources",
    "section": "4.3 Downloadable Data",
    "text": "4.3 Downloadable Data\n\nGuildList.csv\nSalish_Sea_Water_Polygon.dbf\nSalish_Sea_Water_Polygon.prj\nSalish_Sea_Water_Polygon.shp\nSalish_Sea_Water_Polygon.shx\nSalish_Sea_Watershed.dbf\nSalish_Sea_Watershed.prj\nSalish_Sea_Watershed.shp\nSalish_Sea_Watershed.shx",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Resources</span>"
    ]
  },
  {
    "objectID": "99_Resources.html#9.91BirdsCan",
    "href": "99_Resources.html#9.91BirdsCan",
    "title": "4  Resources",
    "section": "4.2 Downloadable R Scripts",
    "text": "4.2 Downloadable R Scripts\nYou can download the R scripts used in this analysis below:\n\n00_Setup.R\nAnalysis_iCAR.R\nAnalysis_SPDE.R\nBCCWSClean.R\nPSSSClean.R\nGraph_iCAR.R\nGraph_SPDE.R\nOutputTables.R\nPSSSBMDE.R",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Resources</span>"
    ]
  },
  {
    "objectID": "99_Resources.html#9.92BirdsCan",
    "href": "99_Resources.html#9.92BirdsCan",
    "title": "4  Resources",
    "section": "4.3 Downloadable Data",
    "text": "4.3 Downloadable Data\n\nGuildList.csv\nSalish_Sea_Water_Polygon.dbf\nSalish_Sea_Water_Polygon.prj\nSalish_Sea_Water_Polygon.shp\nSalish_Sea_Water_Polygon.shx\nSalish_Sea_Watershed.dbf\nSalish_Sea_Watershed.prj\nSalish_Sea_Watershed.shp\nSalish_Sea_Watershed.shx",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Resources</span>"
    ]
  },
  {
    "objectID": "index.html#acknowledgement",
    "href": "index.html#acknowledgement",
    "title": "Transboundary coastal waterbird trends in the Salish Sea",
    "section": "0.5 Acknowledgement",
    "text": "0.5 Acknowledgement\nThis project was financially supported by the SeaDoc Society, a program of the Karen C. Drayer Wildlife Health Center, School of Veterinary Medicine, University of California, Davis.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Overview</span>"
    ]
  }
]